{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare source domain dataloaders and experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "import tqdm\n",
    "LOAD_EXPERTS = True\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "sys.path.append('../domain-adaptation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_train = pd.read_csv('/Users/nikglukhov/n.glukhov/canonical-paritioned-dataset/shifts_canonical_train.csv')\n",
    "df_dev_in = pd.read_csv('/Users/nikglukhov/n.glukhov/canonical-paritioned-dataset/shifts_canonical_dev_in.csv')\n",
    "df_dev_out = pd.read_csv('/Users/nikglukhov/n.glukhov/canonical-paritioned-dataset/shifts_canonical_dev_out.csv')\n",
    "df_dev = pd.concat([df_dev_in, df_dev_out])\n",
    "\n",
    "domains_train = df_train.climate.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, climate):\n",
    "        self.df = df\n",
    "        if climate is not None:\n",
    "            self.X_source_domain = df[df.climate == climate].iloc[:,6:].copy()\n",
    "            self.y_source_domain = df[df.climate == climate]['fact_temperature'].copy()\n",
    "            self.climate = climate\n",
    "        else:\n",
    "            self.X_source_domain = df.iloc[:,6:].copy()\n",
    "            self.y_source_domain = df['fact_temperature'].copy()\n",
    "            self.climate = climate\n",
    "\n",
    "        assert len(self.X_source_domain) == len(self.y_source_domain)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_source_domain)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = torch.tensor(self.X_source_domain.iloc[index].values).to(torch.float32)\n",
    "        y = torch.tensor(self.y_source_domain.iloc[index]).to(torch.float32)\n",
    "        metadata = {\n",
    "            'climate': self.climate if self.climate is not None else self.df.iloc[index].climate\n",
    "        }\n",
    "        return X, y, metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create source domain loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "source_train_domains_loaders =  {\n",
    "    climate: torch.utils.data.DataLoader(Dataset(df_train, climate), batch_size = batch_size)\n",
    "    for climate in domains_train\n",
    "}\n",
    "train_loader = torch.utils.data.DataLoader(Dataset(df_train, None), batch_size = batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(Dataset(df_dev, climate=None), batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, metadata = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dry',\n",
       " 'mild temperate',\n",
       " 'mild temperate',\n",
       " 'mild temperate',\n",
       " 'dry',\n",
       " 'mild temperate',\n",
       " 'mild temperate',\n",
       " 'tropical',\n",
       " 'mild temperate',\n",
       " 'dry',\n",
       " 'mild temperate',\n",
       " 'dry',\n",
       " 'mild temperate',\n",
       " 'mild temperate',\n",
       " 'mild temperate',\n",
       " 'mild temperate',\n",
       " 'mild temperate',\n",
       " 'mild temperate',\n",
       " 'mild temperate',\n",
       " 'tropical',\n",
       " 'dry',\n",
       " 'tropical',\n",
       " 'dry',\n",
       " 'dry',\n",
       " 'mild temperate',\n",
       " 'tropical',\n",
       " 'mild temperate',\n",
       " 'tropical',\n",
       " 'tropical',\n",
       " 'dry',\n",
       " 'mild temperate',\n",
       " 'mild temperate',\n",
       " 'mild temperate',\n",
       " 'dry',\n",
       " 'mild temperate',\n",
       " 'mild temperate',\n",
       " 'mild temperate',\n",
       " 'dry',\n",
       " 'mild temperate',\n",
       " 'mild temperate',\n",
       " 'dry',\n",
       " 'mild temperate',\n",
       " 'dry',\n",
       " 'dry',\n",
       " 'dry',\n",
       " 'mild temperate',\n",
       " 'tropical',\n",
       " 'dry',\n",
       " 'dry',\n",
       " 'mild temperate',\n",
       " 'mild temperate',\n",
       " 'mild temperate',\n",
       " 'mild temperate',\n",
       " 'mild temperate',\n",
       " 'mild temperate',\n",
       " 'mild temperate',\n",
       " 'mild temperate',\n",
       " 'mild temperate',\n",
       " 'mild temperate',\n",
       " 'tropical',\n",
       " 'mild temperate',\n",
       " 'dry',\n",
       " 'tropical',\n",
       " 'tropical']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['climate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train or Load experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_domains_experts = {}\n",
    "def initializeExperts():\n",
    "\n",
    "    model = nn.Sequential(nn.Linear(123, 1)).to(DEVICE)\n",
    "\n",
    "    for climate in domains_train:\n",
    "        source_domains_experts[climate] = model\n",
    "initializeExperts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dry': Sequential(\n",
       "   (0): Linear(in_features=123, out_features=1, bias=True)\n",
       " ),\n",
       " 'mild temperate': Sequential(\n",
       "   (0): Linear(in_features=123, out_features=1, bias=True)\n",
       " ),\n",
       " 'tropical': Sequential(\n",
       "   (0): Linear(in_features=123, out_features=1, bias=True)\n",
       " )}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_domains_experts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DivideModel(nn.Module):\n",
    "    def __init__(self, original_model, layer=-1):\n",
    "        super(DivideModel, self).__init__()\n",
    "        self.num_ftrs = original_model.fc.in_features\n",
    "        self.num_class = original_model.fc.out_features\n",
    "        self.features = None # Change features here. Example: nn.Sequential(*list(o\"riginal_model.children())[:layer])\n",
    "        self.classifier = None # Change predictor here. Example: nn.Sequential(*list(original_model.children())[layer:])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1, self.num_ftrs)\n",
    "        x = self.classifier(x)\n",
    "        x = x.view(-1, self.num_class)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StudentModel(device, load_path=None):\n",
    "    model = None# Place a backbone model here\n",
    "    ## change some model properties if needed; Ex.:\n",
    "    ## num_ftrs = model.fc.in_features\n",
    "    ## model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    if load_path:\n",
    "        model.load_state_dict(torch.load(load_path))\n",
    "    model = DivideModel(model)\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_mask(features, domains, climate):\n",
    "    mask = (domains == climate).nonzero()\n",
    "    features[(domains == climate).nonzero()[0]] = torch.zeros_like(features[0])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert = source_domains_experts['dry']\n",
    "climate = 'dry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[   0.0000],\n",
       "         [4061.8696],\n",
       "         [3191.2437],\n",
       "         [4059.6096],\n",
       "         [   0.0000],\n",
       "         [4234.9868],\n",
       "         [4177.4487],\n",
       "         [3901.5540],\n",
       "         [4044.8813],\n",
       "         [   0.0000],\n",
       "         [3368.3853],\n",
       "         [   0.0000],\n",
       "         [3109.7329],\n",
       "         [3882.3821],\n",
       "         [3783.6377],\n",
       "         [4123.1855],\n",
       "         [4020.4978],\n",
       "         [4085.1965],\n",
       "         [3799.0383],\n",
       "         [      nan],\n",
       "         [   0.0000],\n",
       "         [3331.3696],\n",
       "         [   0.0000],\n",
       "         [   0.0000],\n",
       "         [3915.4246],\n",
       "         [4016.7466],\n",
       "         [3193.8394],\n",
       "         [3339.3872],\n",
       "         [3094.5400],\n",
       "         [   0.0000],\n",
       "         [4004.0603],\n",
       "         [4033.5818]]),\n",
       " tensor([[4060.4006],\n",
       "         [   0.0000],\n",
       "         [   0.0000],\n",
       "         [   0.0000],\n",
       "         [4030.6379],\n",
       "         [   0.0000],\n",
       "         [   0.0000],\n",
       "         [3901.5540],\n",
       "         [   0.0000],\n",
       "         [4121.7065],\n",
       "         [   0.0000],\n",
       "         [3775.0737],\n",
       "         [   0.0000],\n",
       "         [   0.0000],\n",
       "         [   0.0000],\n",
       "         [   0.0000],\n",
       "         [   0.0000],\n",
       "         [   0.0000],\n",
       "         [   0.0000],\n",
       "         [      nan],\n",
       "         [3829.2371],\n",
       "         [3331.3696],\n",
       "         [3901.9934],\n",
       "         [3884.7461],\n",
       "         [   0.0000],\n",
       "         [4016.7466],\n",
       "         [   0.0000],\n",
       "         [3339.3872],\n",
       "         [3094.5400],\n",
       "         [3690.9421],\n",
       "         [   0.0000],\n",
       "         [   0.0000]]),\n",
       " tensor([[4060.4006],\n",
       "         [4061.8696],\n",
       "         [3191.2437],\n",
       "         [4059.6096],\n",
       "         [4030.6379],\n",
       "         [4234.9868],\n",
       "         [4177.4487],\n",
       "         [   0.0000],\n",
       "         [4044.8813],\n",
       "         [4121.7065],\n",
       "         [3368.3853],\n",
       "         [3775.0737],\n",
       "         [3109.7329],\n",
       "         [3882.3821],\n",
       "         [3783.6377],\n",
       "         [4123.1855],\n",
       "         [4020.4978],\n",
       "         [4085.1965],\n",
       "         [3799.0383],\n",
       "         [   0.0000],\n",
       "         [3829.2371],\n",
       "         [   0.0000],\n",
       "         [3901.9934],\n",
       "         [3884.7461],\n",
       "         [3915.4246],\n",
       "         [   0.0000],\n",
       "         [3193.8394],\n",
       "         [   0.0000],\n",
       "         [   0.0000],\n",
       "         [3690.9421],\n",
       "         [4004.0603],\n",
       "         [4033.5818]])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[features_mask(expert(x_sup.float()).detach(), domain, climate) for climate, expert in source_domains_experts.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x, y_true, metadata in train_loader:\n",
    "    domain = np.array(metadata['climate'])\n",
    "\n",
    "    sup_size = x.shape[0]//2\n",
    "    x_sup = x[:sup_size]\n",
    "    y_sup = y_true[:sup_size]\n",
    "    x_que = x[sup_size:]\n",
    "    y_que = y_true[sup_size:]\n",
    "    domain = domain[:sup_size]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = torch.stack(\n",
    "            [\n",
    "            features_mask(expert(x_sup.float()).detach(), domain, climate)\n",
    "            for climate, expert in source_domains_experts.items()\n",
    "            ], dim=-1)\n",
    "        logits = logits.permute((0, 2, 1))\n",
    "    break\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_true, metadata in train_loader:\n",
    "        \n",
    "    domain = np.array(metadata['climate'])\n",
    "    \n",
    "\n",
    "    sup_size = x.shape[0]//2\n",
    "    x_sup = x[:sup_size]\n",
    "    y_sup = y_true[:sup_size]\n",
    "    x_que = x[sup_size:]\n",
    "    y_que = y_true[sup_size:]\n",
    "    domain = domain[:sup_size]\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for climate, expert in source_domains_experts.items():\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(1, 2, 1, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = fa_selector(1, 2, 1, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x, y_true, metadata in train_loader:\n",
    "    domain = np.array(metadata['climate'])\n",
    "\n",
    "    sup_size = x.shape[0]//2\n",
    "    x_sup = x[:sup_size]\n",
    "    y_sup = y_true[:sup_size]\n",
    "    x_que = x[sup_size:]\n",
    "    y_que = y_true[sup_size:]\n",
    "    domain = domain[:sup_size]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = torch.stack(\n",
    "            [\n",
    "            features_mask(expert(x_sup.float()).detach(), domain, climate)\n",
    "            for climate, expert in source_domains_experts.items()\n",
    "            ], dim=-1)\n",
    "        logits = logits.permute((0, 2, 1))\n",
    "    break\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_loss(input, target):\n",
    "    loss = torch.square(target - input)\n",
    "    loss = torch.mean(loss)\n",
    "    return loss\n",
    "\n",
    "def train_epoch(selector, selector_name, source_domains_experts, student, student_name, \n",
    "                train_loader, grouper, epoch, curr, mask_grouper, split_to_cluster,\n",
    "                device, acc_best=0, tlr=1e-4, slr=1e-4, ilr=1e-3,\n",
    "                batch_size=256, sup_size=24, test_way='id', save=False,\n",
    "                root_dir='data'):\n",
    "    for _, expert in source_domains_experts:\n",
    "        expert.eval()\n",
    "    \n",
    "    student_ce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    \n",
    "    features = student.features\n",
    "    head = student.classifier\n",
    "    features.to(device)\n",
    "    head.to(device)\n",
    "    \n",
    "    all_params = list(features.parameters()) + list(head.parameters())\n",
    "    optimizer_s = optim.Adam(all_params, lr=slr)\n",
    "    optimizer_t = optim.Adam(selector.parameters(), lr=tlr)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    iter_per_epoch = len(train_loader)\n",
    "        \n",
    "    for x, y_true, metadata in train_loader:\n",
    "        selector.eval()\n",
    "        head.eval()\n",
    "        features.eval()\n",
    "        \n",
    "        domain = np.array(metadata['climate'])\n",
    "        \n",
    "    \n",
    "        sup_size = x.shape[0]//2\n",
    "        x_sup = x[:sup_size]\n",
    "        y_sup = y_true[:sup_size]\n",
    "        x_que = x[sup_size:]\n",
    "        y_que = y_true[sup_size:]\n",
    "        domain = domain[:sup_size]\n",
    "\n",
    "        x_sup = x_sup.to(device)\n",
    "        y_sup = y_sup.to(device)\n",
    "        x_que = x_que.to(device)\n",
    "        y_que = y_que.to(device)\n",
    "        \n",
    "\n",
    "        _squeeze = True\n",
    "        with torch.no_grad():\n",
    "            logits = torch.stack(\n",
    "                [\n",
    "                features_mask(expert(x_sup).detach(), domain, climate)\n",
    "                for climate, expert in source_domains_experts.items()\n",
    "                ], dim=-1)\n",
    "            ### Expert input: [BS, 123]; Expert output: [BS, N]\n",
    "            ### logits -> [BS, N, 3].\n",
    "            logits = logits.permute((0,2,1))\n",
    "                \n",
    "            \n",
    "            #logits = torch.stack([expert(x_sup).detach() for expert in experts_list], dim=-1)\n",
    "            #logits[:, :, split_to_cluster[z]] = torch.zeros_like(logits[:, :, split_to_cluster[z]])\n",
    "            #\n",
    "            #logits = mask_feat(logits, mask, len(models_list), exclude=True)\n",
    "        \n",
    "        t_out = selector.get_feat(logits)  \n",
    "\n",
    "        task_model = features.clone()\n",
    "        task_model.module.eval()\n",
    "        feat = task_model(x_que)\n",
    "        feat = feat.view(feat.shape[0], -1)\n",
    "        out = head(feat)\n",
    "        with torch.no_grad():\n",
    "            loss_pre = student_ce(out, y_que.unsqueeze(-1).float()).item()/x_que.shape[0]\n",
    "        \n",
    "        feat = task_model(x_sup)\n",
    "        feat = feat.view_as(t_out)\n",
    "\n",
    "        inner_loss = l2_loss(feat, t_out)\n",
    "        task_model.adapt(inner_loss)\n",
    "        \n",
    "        x_que = task_model(x_que)\n",
    "        x_que = x_que.view(x_que.shape[0], -1)\n",
    "        s_que_out = head(x_que)\n",
    "        s_que_loss = student_ce(s_que_out, y_que.unsqueeze(-1).float())\n",
    "        #t_sup_loss = teacher_ce(t_out, y_sup)\n",
    "        \n",
    "        s_que_loss.backward()\n",
    "        \n",
    "        optimizer_s.step()\n",
    "        optimizer_t.step()\n",
    "        optimizer_s.zero_grad()\n",
    "        optimizer_t.zero_grad()\n",
    "        \n",
    "        ### Print some validation info\n",
    "        ### Code here\n",
    "        ###\n",
    "\n",
    "        losses.append(s_que_loss.item()/x_que.shape[0])\n",
    "        \n",
    "            \n",
    "        i += 1\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kd(selector, selector_name, models_list, student, student_name, split_to_cluster, device,\n",
    "             batch_size=256, sup_size=24, tlr=1e-4, slr=1e-4, ilr=1e-5, num_epochs=30,\n",
    "             decayRate=0.96, save=False, test_way='ood', root_dir='data'):\n",
    "    \n",
    "    train_loader = get_data_loader()\n",
    "    for epoch in range(num_epochs):\n",
    "        some_train_loss_value = train_epoch(selector, selector_name, models_list, student, student_name, \n",
    "                                train_loader, grouper, epoch, curr, mask_grouper, split_to_cluster,\n",
    "                                device, acc_best=accu_best, tlr=tlr, slr=slr, ilr=ilr,\n",
    "                                batch_size=batch_size, sup_size=sup_size, test_way=test_way, save=save,\n",
    "                                root_dir=root_dir) # need to remove some input variables\n",
    "        some_eval_loss_value = eval(selector, models_list, student, sup_size, device=device, \n",
    "                    ilr=ilr, test=False, progress=False, uniform_over_groups=False,\n",
    "                    root_dir=root_dir)\n",
    "\n",
    "        ### \n",
    "        # print results\n",
    "        # save model\n",
    "\n",
    "        tlr = tlr*decayRate\n",
    "        slr = slr*decayRate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e3f43fd401cdc46c7579e2b5a1ac9f12820ab8bd56f17154833f004e8ad52f07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
